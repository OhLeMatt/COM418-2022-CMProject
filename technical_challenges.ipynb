{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import music_tools.midi_utils as mu\n",
    "from music_tools.midi_frame import MidiFrame\n",
    "import music_tools.scales as scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the spring semester 2022, we had to develop a project for EPFL's Master course **Computer and Music** (COM-418) given by Prof. Paolo Prandoni. \n",
    "\n",
    "Our proposal was to create a software tool capable of:\n",
    "* Reading, visualizing and playing MIDI files' music.\n",
    "* Suggesting and showing related musical knowledge for improvisation in real-time.\n",
    "\n",
    "The first part essentially requires to have well treated MIDI files as we don't want to edit them, but to visua\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing Midi Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating An Interesting Musical Scale Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating Between Scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chord Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Work\\MA4\\CompMus\\COM418-2022-CMProject\\technical_challenges.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Work/MA4/CompMus/COM418-2022-CMProject/technical_challenges.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(mf\u001b[39m.\u001b[39mplaying_track_frame)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/MA4/CompMus/COM418-2022-CMProject/technical_challenges.ipynb#ch0000002?line=1'>2</a>\u001b[0m mf\u001b[39m.\u001b[39mmake_playing_track_frame([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m16\u001b[39m)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/MA4/CompMus/COM418-2022-CMProject/technical_challenges.ipynb#ch0000002?line=3'>4</a>\u001b[0m mu\u001b[39m.\u001b[39mplot_music(mf\u001b[39m.\u001b[39mplaying_track_frame\u001b[39m.\u001b[39mget_sub_dataframe(\u001b[39m0\u001b[39m, \u001b[39m100\u001b[39m), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/MA4/CompMus/COM418-2022-CMProject/technical_challenges.ipynb#ch0000002?line=4'>5</a>\u001b[0m               metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbartime\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/MA4/CompMus/COM418-2022-CMProject/technical_challenges.ipynb#ch0000002?line=5'>6</a>\u001b[0m               chroma_plot\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mf' is not defined"
     ]
    }
   ],
   "source": [
    "print(mf.playing_track_frame)\n",
    "mf.make_playing_track_frame([i for i in range(16)])\n",
    "\n",
    "mu.plot_music(mf.playing_track_frame.get_sub_dataframe(0, 100), \n",
    "              metric=\"bartime\",\n",
    "              chroma_plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "suggestions = mf.playing_track_frame.suggest_scale(\n",
    "    start=0,\n",
    "    end=4,\n",
    "    weighted=False,\n",
    "    normalize_accuracy=True,\n",
    "    threshold=0.9,\n",
    "    general_scale_subset=scales.create_general_scale_subset(note_counts=[7])\n",
    "    # general_scale_subset=[scales.scale(3753),scales.scale(2741)]\n",
    "    # general_scale_subset=[scales.scale(2741)]\n",
    "    )\n",
    "\n",
    "# for scale, accuracy in suggestions:\n",
    "#     print(scale, \":\", f\"{int(accuracy*100)}%\")\n",
    "# scale = suggestions[0][0]\n",
    "# for s in scale.rotated_scales():\n",
    "#     print(s, s.chromas_name)\n",
    "\n",
    "for gs in scales.ALL_GENERAL_ROTZERO_SCALES:\n",
    "    scale_list = gs.scale_in(1).rotated_scales()\n",
    "    common_set = set(scale_list[0].chromas)\n",
    "    for s in scale_list[1:]:\n",
    "        other_set = set(s.chromas)\n",
    "        if common_set != other_set:\n",
    "            print(scale_list[0].chromas, \"vs\", s)\n",
    "            print(\"\\t\", common_set)\n",
    "            print(\"\\t\", other_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05 ms ± 59.1 µs per loop (mean ± std. dev. of 4 runs, 300 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 4 -n 300 suggestions = mf.playing_track_frame.suggest_scale(start=0, end=100, weighted=False, normalize_accuracy=True, threshold=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.5,  1. ],\n",
       "       [10.5, 11. , 11.5],\n",
       "       [ 3. ,  3.5,  4. ],\n",
       "       [13.5, 14. , 14.5],\n",
       "       [ 6. ,  6.5,  7. ],\n",
       "       [16.5, 17. , 17.5],\n",
       "       [ 9. ,  9.5, 10. ],\n",
       "       [ 1.5,  2. ,  2.5],\n",
       "       [12. , 12.5, 13. ],\n",
       "       [ 4.5,  5. ,  5.5],\n",
       "       [15. , 15.5, 16. ],\n",
       "       [ 7.5,  8. ,  8.5],\n",
       "       [ 0. ,  0.5,  1. ],\n",
       "       [10.5, 11. , 11.5],\n",
       "       [ 3. ,  3.5,  4. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = np.arange(36).reshape(12,3)\n",
    "indices = np.arange(0, 100, 7)%12\n",
    "weight = np.ones(len(indices)) / 2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a745e65f00ba40f4710b3eb53765bd6a652c39d81dd3857a25c705af3598b4bd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
